





==================================================
It requires that the training data not be shuffled when fitting the network.
 It also requires explicit resetting of the network state after each exposure to
 the training data (epoch) by calls to model.reset_states(). This
 means that we must create our own outer loop of epochs and within each epoch call
 model.fit() and model.reset_states(). For example:

for i in range(100):
	model.fit(trainX, trainY, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)
	model.reset_states()

Finally, when the LSTM layer is constructed, the stateful parameter must be set True and instead of specifying the input dimensions, we must hard code the number of samples in a batch, number of time steps in a sample and number of features in a time step by setting the batch_input_shape parameter. For example:

model.add(LSTM(4, batch_input_shape=(batch_size, time_steps, features), stateful=True))

model.add(LSTM(4, batch_input_shape=(batch_size, time_steps, features), stateful=True))
This same batch size must then be used later when evaluating the model and making predictions. For example:

model.predict(trainX, batch_size=batch_size)

model.predict(trainX, batch_size=batch_size)
==================================================

2) Reshaping the data is ALSO different
# reshape input to be [samples, time steps, features]
trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))
testX = numpy.reshape(testX, (testX.shape[0], testX.shape[1], 1))

This is as opposed to the features coming first
==================================================

3)AND most importantly, in the LSTM module
we use batch input shape, as opposed to the input shape
or using time distributed.
model.add(LSTM(4, batch_input_shape=(batch_size, look_back, num_features), stateful=True))
==============================================
4) WHEN stacking LSTMS, need to return_sequences=True
Stacked LSTMs with Memory Between Batches
eg:
model.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))
model.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True))